{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f90300db390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv2d, MaxPool2d, Dropout, BatchNorm2d, ReLU, Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "torch.manual_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"../../DATASETS/classification_datasets/face_expression_recognation/train\"\n",
    "test_data_path = \"../../DATASETS/classification_datasets/face_expression_recognation/validation\"\n",
    "device=torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "epochs=50\n",
    "learning_rate=3e-4\n",
    "momentum=0.9\n",
    "batch_size = 16\n",
    "num_classes=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognationDataset(Dataset):\n",
    "    def __init__(self, data_path, transforms=None):\n",
    "        super(FaceRecognationDataset, self)\n",
    "        self.data_path=data_path\n",
    "        self.transforms=transforms\n",
    "        self.classes = os.listdir(data_path)\n",
    "\n",
    "        images_path = []\n",
    "        labels_dict = {}\n",
    "\n",
    "        for i, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(data_path, class_name)\n",
    "            for image_path in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_path)\n",
    "                images_path.append(image_path)\n",
    "                labels_dict[image_path] = i\n",
    "\n",
    "        self.images_path_list = images_path\n",
    "        self.labels_dict = labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image_path = self.images_path_list[index]\n",
    "        label = self.labels_dict[image_path]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms != None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = transforms.Compose([\n",
    "    transforms.Resize(308),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceRecognationDataset(train_data_path, transforms=my_transforms)\n",
    "test_dataset = FaceRecognationDataset(test_data_path, transforms=my_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 28821\n",
      "Test set: 7066\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {len(train_dataset)}\")\n",
    "print(f\"Test set: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 3993,\n",
       " 'happy': 7164,\n",
       " 'surprise': 3205,\n",
       " 'sad': 4938,\n",
       " 'neutral': 4982,\n",
       " 'disgust': 436,\n",
       " 'fear': 4103}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(train_data_path)\n",
    "dist_dict = {}\n",
    "for class_name in classes:\n",
    "    single_class_path = os.path.join(train_data_path, class_name)\n",
    "    num_files = len(os.listdir(single_class_path))\n",
    "    dist_dict[class_name] = num_files\n",
    "dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = list(dist_dict.keys())\n",
    "counts = list(dist_dict.values())\n",
    "fig, ax = plt.subplots()\n",
    "bars = plt.bar(classes, counts, color='blue')\n",
    "\n",
    "# Add annotations on top of each bar\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{count}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Items')\n",
    "plt.title('Class Distribution with Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, act = False, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.act = act\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        if self.act == True:\n",
    "            return F.relu(x)\n",
    "        else: \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, act=False):\n",
    "        super(SeparableConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.act = act\n",
    "\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size = 3, groups=in_channels, padding=1)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        if self.act == True:\n",
    "            x = F.relu(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.batchnorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleFlow(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(MiddleFlow, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "        \n",
    "        self.block6 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "\n",
    "        self.block7 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "        \n",
    "        self.block8 = nn.Sequential(\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True),\n",
    "            SeparableConv(channels, channels, act=True))\n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        fusion1 = x + block1\n",
    "\n",
    "        block2 = self.block2(fusion1)\n",
    "        fusion2 = fusion1 + block2\n",
    "\n",
    "        block3 = self.block3(fusion2)\n",
    "        fusion3 = fusion2 + block3\n",
    "\n",
    "        block4 = self.block4(fusion3)\n",
    "        fusion4 = fusion3 + block4\n",
    "\n",
    "        block5 = self.block5(fusion4)\n",
    "        fusion5 = fusion4 + block5\n",
    "\n",
    "        block6 = self.block6(fusion5)\n",
    "        fusion6 = fusion5 + block6\n",
    "\n",
    "        block7 = self.block7(fusion6)\n",
    "        fusion7 = fusion6 + block7\n",
    "\n",
    "        block8 = self.block8(fusion7)\n",
    "        fusion8 = fusion7 + block8\n",
    "\n",
    "        return fusion8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Xception, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Entry flow\n",
    "        self.conv1 = ConvBlock(in_channels, 32, kernel_size=3, stride=2, act=True)\n",
    "        self.conv2 = ConvBlock(32, 64, kernel_size=3, act=True)\n",
    "        self.residual1 = ConvBlock(64, 128, kernel_size=1, stride=2)\n",
    "\n",
    "        self.sepconv1 = SeparableConv(64, 128)\n",
    "        self.sepconv2 = SeparableConv(128, 128, act=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual2 = ConvBlock(128, 256, kernel_size=1, stride=2)\n",
    "\n",
    "        self.sepconv3 = SeparableConv(128, 256, act=True)\n",
    "        self.sepconv4 = SeparableConv(256, 256, act=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual3 = ConvBlock(256, 728, kernel_size=1, stride=2)\n",
    "\n",
    "        self.sepconv5 = SeparableConv(256, 728, act=True)\n",
    "        self.sepconv6 = SeparableConv(728, 728, act=True)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Middle flow\n",
    "        self.middleflow = MiddleFlow(728)\n",
    "\n",
    "        # Exit Flow\n",
    "        self.exitsep1 = SeparableConv(728, 728, act=True)\n",
    "        self.exitsep2 = SeparableConv(728, 1024, act=True)\n",
    "        self.exitmaxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.exitresidual = ConvBlock(728, 1024, kernel_size=1, stride=2)\n",
    "\n",
    "        self.exitsep3 = SeparableConv(1024, 1536)\n",
    "        self.exitsep4 = SeparableConv(1536, 2048)\n",
    "        self.globalavgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Entry Flow\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        res1 = self.residual1(conv2)\n",
    "        \n",
    "        sep1 = self.sepconv1(conv2)\n",
    "        sep2 = self.sepconv2(sep1)\n",
    "        pool1 = self.maxpool1(sep2)\n",
    "        fusion1 = pool1 + res1\n",
    "        res2 = self.residual2(fusion1)\n",
    "\n",
    "        sep3 = self.sepconv3(fusion1)\n",
    "        sep4 = self.sepconv4(sep3)\n",
    "        pool2 = self.maxpool2(sep4)\n",
    "        fusion2 = pool2 + res2\n",
    "        res3 = self.residual3(fusion2)\n",
    "\n",
    "        sep5 = self.sepconv5(fusion2)\n",
    "        sep6 = self.sepconv6(sep5)\n",
    "        pool3 = self.maxpool3(sep6)\n",
    "        fusion3 = pool3 + res3\n",
    "\n",
    "        # Middle Flow\n",
    "        middleflow = self.middleflow(fusion3)\n",
    "\n",
    "        # Exit Flow\n",
    "        exitsep1 = self.exitsep1(middleflow)\n",
    "        exitsep2 = self.exitsep2(exitsep1)\n",
    "        exitmaxpool = self.exitmaxpool(exitsep2)\n",
    "        exitresidual = self.exitresidual(middleflow)\n",
    "        exitfusion = exitresidual + exitmaxpool\n",
    "\n",
    "        exitsep3 = F.relu(self.exitsep3(exitfusion))\n",
    "        exitsep4 = F.relu(self.exitsep4(exitsep3))\n",
    "        globalavgpool = self.globalavgpool(exitsep4)\n",
    "        dropped = self.dropout(globalavgpool)\n",
    "        x = torch.flatten(dropped, start_dim=1)\n",
    "        classifier = self.classifier(x)\n",
    "\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Xception(3, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=momentum)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Custom Learning Rate Scheduler \n",
    "def adjust_learning_rate(optimizer, epoch, initial_lr, decay_rate):\n",
    "    # Exponential decay every 10 epochs\"\n",
    "    if epoch % 5 == 0:\n",
    "        lr = initial_lr * torch.exp(torch.tensor(-decay_rate*epoch))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch(device, model, loader, optimizer, criterion):\n",
    "    loop = tqdm(loader)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_id, (images, labels) in enumerate(loop):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        output = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        batch_correct = (predicted==labels).sum().item()\n",
    "        batch_acc = 100*batch_correct/labels.size(0)\n",
    "        correct += batch_correct\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(train_loss = loss.item(), train_accuracy = batch_acc)\n",
    "        \n",
    "    return np.mean(losses), 100*correct/total\n",
    "\n",
    "def testEpoch(device, model, loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        loop = tqdm(loader)\n",
    "        for batch_id, (images, labels) in enumerate(loop):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            output = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += labels.size(0)\n",
    "            batch_correct = (predicted==labels).sum().item()\n",
    "            batch_acc = 100*batch_correct/labels.size(0)\n",
    "            correct += batch_correct\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            losses.append(loss.item())\n",
    "            loop.set_postfix(test_loss = loss.item(), test_accuracy = batch_acc)\n",
    "\n",
    "        return np.mean(losses), 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:33<00:00,  6.59it/s, train_accuracy=60, train_loss=1.2]    \n",
      "100%|██████████| 442/442 [00:24<00:00, 17.94it/s, test_accuracy=60, test_loss=1.1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new Best Model!\n",
      "Epoch-1 Train Loss: 1.4424 Train Accuracy: 43.6695\n",
      "Epoch-1 Test Loss: 1.3521 Test Accuracy: 49.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:30<00:00,  6.67it/s, train_accuracy=100, train_loss=0.816] \n",
      "100%|██████████| 442/442 [00:24<00:00, 18.16it/s, test_accuracy=50, test_loss=1.67]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new Best Model!\n",
      "Epoch-2 Train Loss: 1.1966 Train Accuracy: 54.5713\n",
      "Epoch-2 Test Loss: 1.1260 Test Accuracy: 57.7271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:30<00:00,  6.65it/s, train_accuracy=80, train_loss=1.38]   \n",
      "100%|██████████| 442/442 [00:25<00:00, 17.64it/s, test_accuracy=60, test_loss=1.22]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new Best Model!\n",
      "Epoch-3 Train Loss: 1.0940 Train Accuracy: 59.1374\n",
      "Epoch-3 Test Loss: 1.0569 Test Accuracy: 59.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:33<00:00,  6.59it/s, train_accuracy=40, train_loss=0.818]  \n",
      "100%|██████████| 442/442 [00:24<00:00, 18.14it/s, test_accuracy=60, test_loss=0.917]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new Best Model!\n",
      "Epoch-4 Train Loss: 0.9993 Train Accuracy: 62.4961\n",
      "Epoch-4 Test Loss: 1.0094 Test Accuracy: 62.7371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:34<00:00,  6.56it/s, train_accuracy=80, train_loss=0.526]  \n",
      "100%|██████████| 442/442 [00:24<00:00, 18.10it/s, test_accuracy=70, test_loss=0.983]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-5 Train Loss: 0.8993 Train Accuracy: 66.5973\n",
      "Epoch-5 Test Loss: 1.0293 Test Accuracy: 62.3549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:36<00:00,  6.52it/s, train_accuracy=100, train_loss=0.221] \n",
      "100%|██████████| 442/442 [00:24<00:00, 17.92it/s, test_accuracy=70, test_loss=0.756]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new Best Model!\n",
      "Epoch-6 Train Loss: 0.6768 Train Accuracy: 75.2646\n",
      "Epoch-6 Test Loss: 1.0104 Test Accuracy: 65.4967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:35<00:00,  6.54it/s, train_accuracy=100, train_loss=0.392]  \n",
      "100%|██████████| 442/442 [00:24<00:00, 17.97it/s, test_accuracy=60, test_loss=1.09]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-7 Train Loss: 0.4500 Train Accuracy: 83.9180\n",
      "Epoch-7 Test Loss: 1.1682 Test Accuracy: 64.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:36<00:00,  6.52it/s, train_accuracy=100, train_loss=0.0431] \n",
      "100%|██████████| 442/442 [00:24<00:00, 17.77it/s, test_accuracy=60, test_loss=1.15]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-8 Train Loss: 0.2413 Train Accuracy: 91.8775\n",
      "Epoch-8 Test Loss: 1.4533 Test Accuracy: 61.7464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:54<00:00,  6.13it/s, train_accuracy=60, train_loss=0.832]   \n",
      "100%|██████████| 442/442 [00:24<00:00, 17.73it/s, test_accuracy=60, test_loss=2.97]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-9 Train Loss: 0.1737 Train Accuracy: 94.3618\n",
      "Epoch-9 Test Loss: 1.5793 Test Accuracy: 63.7843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:33<00:00,  6.60it/s, train_accuracy=100, train_loss=0.0095] \n",
      "100%|██████████| 442/442 [00:24<00:00, 18.13it/s, test_accuracy=50, test_loss=2.85]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-10 Train Loss: 0.1361 Train Accuracy: 95.7184\n",
      "Epoch-10 Test Loss: 1.7445 Test Accuracy: 62.7371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:29<00:00,  6.69it/s, train_accuracy=100, train_loss=0.00574] \n",
      "100%|██████████| 442/442 [00:25<00:00, 17.43it/s, test_accuracy=80, test_loss=1.6]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-11 Train Loss: 0.0715 Train Accuracy: 98.1507\n",
      "Epoch-11 Test Loss: 1.7154 Test Accuracy: 65.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:34<00:00,  6.56it/s, train_accuracy=80, train_loss=0.273]    \n",
      "100%|██████████| 442/442 [00:24<00:00, 17.76it/s, test_accuracy=40, test_loss=3.25]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-12 Train Loss: 0.0561 Train Accuracy: 98.6191\n",
      "Epoch-12 Test Loss: 1.8006 Test Accuracy: 64.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:33<00:00,  6.60it/s, train_accuracy=100, train_loss=0.0273]  \n",
      "100%|██████████| 442/442 [00:24<00:00, 18.05it/s, test_accuracy=90, test_loss=0.693]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-13 Train Loss: 0.0514 Train Accuracy: 98.6815\n",
      "Epoch-13 Test Loss: 1.9997 Test Accuracy: 64.2938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:35<00:00,  6.54it/s, train_accuracy=100, train_loss=0.0157]  \n",
      "100%|██████████| 442/442 [00:24<00:00, 18.28it/s, test_accuracy=40, test_loss=3.09]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-14 Train Loss: 0.0485 Train Accuracy: 98.6468\n",
      "Epoch-14 Test Loss: 2.0104 Test Accuracy: 64.7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:35<00:00,  6.54it/s, train_accuracy=80, train_loss=0.537]    \n",
      "100%|██████████| 442/442 [00:24<00:00, 17.89it/s, test_accuracy=50, test_loss=2.42]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-15 Train Loss: 0.0468 Train Accuracy: 98.7232\n",
      "Epoch-15 Test Loss: 1.9781 Test Accuracy: 64.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [04:31<00:00,  6.63it/s, train_accuracy=80, train_loss=0.659]    \n",
      "100%|██████████| 442/442 [00:25<00:00, 17.31it/s, test_accuracy=50, test_loss=2.59]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-16 Train Loss: 0.0237 Train Accuracy: 99.3477\n",
      "Epoch-16 Test Loss: 2.0337 Test Accuracy: 65.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 578/1802 [01:28<02:58,  6.86it/s, train_accuracy=100, train_loss=0.0141]  "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "last_best = 0\n",
    "train_losses = []\n",
    "train_acc = []\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "for epoch in range (epochs):\n",
    "    \n",
    "    train_loss, train_accuracy = trainEpoch(device, model, train_loader, optimizer, criterion)\n",
    "    test_loss, test_accuracy = testEpoch(device, model, test_loader, criterion)\n",
    "    adjust_learning_rate(optimizer, epoch+1, learning_rate, 0.1)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc.append(test_accuracy)\n",
    "\n",
    "    # scheduler.step()\n",
    "\n",
    "    if last_best <= test_accuracy:\n",
    "        torch.save(copy.deepcopy(model.state_dict()), 'xception.pth')\n",
    "        print(\"Saving new Best Model!\")\n",
    "        last_best = test_accuracy\n",
    "\n",
    "    print(f\"Epoch-{epoch+1} Train Loss: {train_losses[-1]:.4f} Train Accuracy: {train_acc[-1]:.4f}\")\n",
    "    print(f\"Epoch-{epoch+1} Test Loss: {test_losses[-1]:.4f} Test Accuracy: {test_acc[-1]:.4f}\")\n",
    "\n",
    "dict = {'train_loss': train_losses, 'train_accuracy': train_acc, 'test_loss': test_losses, 'test_accuracy': test_acc}\n",
    "df = pd.DataFrame(dict)\n",
    "df.to_csv('loss_and_acc_xception.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = df[\"train_loss\"]\n",
    "train_acc = df[\"train_accuracy\"]\n",
    "valid_loss = df[\"test_loss\"]\n",
    "valid_acc = df[\"test_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label=\"Train loss\")\n",
    "plt.plot(valid_loss, label=\"Validation loss\")\n",
    "plt.title(\"Loss per epoch\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label=\"Train accuracy\")\n",
    "plt.plot(valid_acc, label=\"Validation accuracy\")\n",
    "plt.title(\"Accuracy per epoch\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's load the trained model\n",
    "model = Xception(in_channels=3, num_classes=7)\n",
    "model.load_state_dict(torch.load(\"xception.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model = model.to(device)\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in tqdm(test_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "       \n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        model=model.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, true_labels, predicted_labels, nrows, ncols, classes):\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 10))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Convert the tensor image to a NumPy array\n",
    "        img = images[i]\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        true_label = classes[true_labels[i]]\n",
    "        predicted_label = classes[predicted_labels[i]]\n",
    "\n",
    "        # Display the image\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # Display the label below the image\n",
    "        if true_label == predicted_label:\n",
    "            font_color  = \"green\"\n",
    "        else:\n",
    "            font_color = \"red\"\n",
    "        ax.set_xlabel(f\"GT: {true_label} | Predicted: {predicted_label}\", color=font_color)\n",
    "\n",
    "        # Remove ticks and labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_facecolor(\"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, true_labels = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "model = model.to(device)\n",
    "outputs = model(images)\n",
    "_, predicted_labels = torch.max(outputs.data, 1)\n",
    "true_labels = true_labels.numpy()\n",
    "predicted_labels = predicted_labels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(images, true_labels, predicted_labels, 4,4, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ict11-smp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
